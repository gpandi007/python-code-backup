{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling approach 1 run the model in live database and run with test data - take 3 min time to load all the data\n",
    "# Modeling approach 2 save the model and run with test data - it does not take time \n",
    "\n",
    "# save the model to disk\n",
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))\n",
    "# some time later...######### preprocess test data alone to test the prediction results\n",
    "# load the model from disk\n",
    "\n",
    "# read testdata #########################################################################\n",
    "# read testdata, #Missing value Imputation, # Remove CORRILATION VARIYABLE \n",
    "# drop date # remove top 10 missing variables # Remove below variable as it has only one value # normalize the data \n",
    "# drop after normalization # Label Encoding model\n",
    "# data conversion  # define the y variable #QuantileTransformer \n",
    "# remove max VIF variables #features selection #misc_feat - drop the remaining features \n",
    "# drop the sting data #Splitting the values for X_train and Y_train \n",
    "# get only serial number form test data # pass x test to get the prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55855b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-783ff4cf0c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# accuraccy score with test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuraccy_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# final prediction results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# accuraccy score with test data\n",
    "accuraccy_result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n",
    "# final prediction results \n",
    "prediction_result=loaded_model.predict(X_test)\n",
    "prediction_result\n",
    "#Model_Prediction dataframe\n",
    "Model_Prediction = pd.DataFrame(prediction_result, columns =['Model_Prediction'])\n",
    "print(\"\\nPandas DataFrame: \")\n",
    "Model_Prediction\n",
    "df_test_serial_number=pd.DataFrame(df_test_serial_number)\n",
    "Model_Prediction['row_num'] = np.arange(len(Model_Prediction))\n",
    "df_test_serial_number['row_num'] = np.arange(len(df_test_serial_number))\n",
    "#result = pd.concat([Model_Prediction, df_test_serial_number], axis=1)\n",
    "# Stack the Data Frames on top of each other\n",
    "Model_Prediction.Model_Prediction.replace((0, 1), ('not_fail', 'Predicted_to_be_fail'), inplace=True)\n",
    "RandomForest_Model_Prediction=df_test_serial_number.merge(Model_Prediction, on='row_num', how='left')\n",
    "RandomForest_Model_Prediction = RandomForest_Model_Prediction.drop(['row_num'], 1)\n",
    "RandomForest_Model_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ccc359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14ff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
